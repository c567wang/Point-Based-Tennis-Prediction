{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook merges the player information in the matches files and the point by point data in the points files. Only fields that will be needed in the extraction notebook will be written to the resulting csv. For now that means the 2 player names, the point server, the point winner and the score of the respective players after the point. More can be added in the future if needed (add to end of f_fields list!).\n",
    "\n",
    "Note we use names rather than ids because there does not seem to be any consistency between the pbp datasets and the earlier match aggregate sets. Additionally, not all id fields are populated throughout the pbp datasets, while names are, so we can't even use the ids for pbp consolidation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# information to change per use\n",
    "# only set we don't have is 2020 wimbledon which was cancelled\n",
    "year = \"2011\"\n",
    "points_file = year+\"-frenchopen-points.csv\"\n",
    "matches_file = year+\"-frenchopen-matches.csv\"\n",
    "return_file = year+\"-frenchopen-pbp.csv\"\n",
    "# surface = \"hard\" # valid options: \"grass\",\"hard\",\"clay\"\n",
    "f_fields = [\"P1\",\"P2\",\"match_id\",\"PointServer\",\"PointWinner\",\"P1Score\",\"P2Score\",\"SetNo\"] # match_id is the key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd() # \"...\\\\Code\"\n",
    "path = path[:-4]+\"New Data\\\\pbp\\\\\" # all involved files use this same path\n",
    "points_path = path+points_file\n",
    "matches_path = path+matches_file\n",
    "return_path = path+return_file\n",
    "# return_path = path+\"set5\\\\\"+return_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = [] # each item to be a dict containing info on a single point\n",
    "\n",
    "# go through points data and keep specified fields\n",
    "with open(points_path,'r') as f:\n",
    "    \n",
    "    csvreader = csv.reader(f)\n",
    "    fields = next(csvreader)\n",
    "    \n",
    "    for row in csvreader:\n",
    "        # initialize point dict\n",
    "        # only need first two as rest initialized upon entry below\n",
    "        \n",
    "        # this block inserted later to extract 5th set specific points\n",
    "        # will be commented out after use\n",
    "        # if row[fields.index(\"SetNo\")]=='5':\n",
    "        #     continue\n",
    "        \n",
    "        point = {}\n",
    "        point[\"P1\"] = \"\"\n",
    "        point[\"P2\"] = \"\"\n",
    "        for field in f_fields[2:]:\n",
    "            point[field] = row[fields.index(field)]\n",
    "        points.append(point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now using match_id fill in \"P1\",\"P2\"\n",
    "with open(matches_path,'r') as f:\n",
    "    \n",
    "    csvreader = csv.reader(f)\n",
    "    fields = next(csvreader)\n",
    "    match_id = fields.index(\"match_id\")\n",
    "    P1 = fields.index(\"player1\")\n",
    "    P2 = fields.index(\"player2\")\n",
    "    i = 0\n",
    "    for row in csvreader:\n",
    "        try:\n",
    "            while row[match_id]==points[i][\"match_id\"]:\n",
    "                points[i][\"P1\"] = row[P1]\n",
    "                points[i][\"P2\"] = row[P2]\n",
    "                i += 1\n",
    "        except IndexError:\n",
    "            if i==len(points):\n",
    "                pass\n",
    "            else:\n",
    "                print(\"Indexing Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no need for match_id anymore\n",
    "f_fields.remove(\"match_id\")\n",
    "for point in points:\n",
    "    point.pop(\"match_id\")\n",
    "\n",
    "# writing points list\n",
    "with open(return_path,'w',newline=\"\") as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=f_fields)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(points)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
