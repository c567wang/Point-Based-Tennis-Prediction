{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraction of head-to-head (H2H) data targeting the 2022 testing datasets, as well as common-opponent (CO) data. The data is stored in separate files. By construction, for the same matchup, the h2h and co datasets will be disjoint.\n",
    "\n",
    "This new version does extraction for CO2 and CO2NSF as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# information to specify before running file (just first 2, rest is automated)\n",
    "tour = \"atp\"\n",
    "target_year = 2022\n",
    "target_name = tour+\"_testing_\"+str(target_year)+\".csv\" # file containing matches the data is to be collected for\n",
    "f_names = [] # corresponding three year horizon to collect h2h, co, co2 data\n",
    "for i in range(3):\n",
    "    f_names.append(tour+\"_matches_\"+str(target_year-1-i)+\".csv\")\n",
    "# result files\n",
    "h2h_name = str(target_year-3)+\"-\"+str(target_year-1)+\"_\"+tour+\"_h2h.csv\" # e.g., \"2011-2013_wta_h2h.csv\"\n",
    "co_name = str(target_year-3)+\"-\"+str(target_year-1)+\"_\"+tour+\"_co.csv\"\n",
    "# co2 and co2nsf in the same csv as co, their surfaces being fixed reduces the # of columns they take up\n",
    "# fields to extract, two of the same to account for the 2 players\n",
    "f_fields = [\"surface\"]\n",
    "for i in range(2): # 1(2) is the winner(loser) in the testing data\n",
    "    f_fields.append(\"id\"+str(i+1))\n",
    "    for surface in [\"grass\",\"hard\",\"clay\",\"carpet\",\"co2\",\"co2nsf\"]: # co2 is the surface in the \"surface\" field\n",
    "        for stat in [\"_pts_served\",\"_service_pts_won\",\"_pts_received\",\"_receiving_pts_won\",\"_aces\",\"_sample_size\"]:\n",
    "            f_fields.append(surface+stat+str(i+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get paths\n",
    "path = os.getcwd() # \"...\\\\Code\" parallel with \"New Data\"\n",
    "matches_path = path[:-4]+\"New Data\\\\\"+tour+\"\\\\raw\" # folder containing matches to mine\n",
    "players_path = path[:-4]+\"New Data\\\\\"+tour # folder to store all extracted stats\n",
    "target_path = path[:-4]+\"New Data\\\\\"+tour # folder containing testing targets\n",
    "t_path = target_path+\"\\\\\"+target_name\n",
    "h2h_path = players_path+\"\\\\\"+h2h_name\n",
    "co_path = players_path+\"\\\\\"+co_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# each match's player stats to be stored in a dict in an overall list\n",
    "# list will be go by order of matches in the target file\n",
    "ovr_list_h2h = []\n",
    "# deep copies later for co and co2\n",
    "\n",
    "# initializing ovr_list with matches from the target csv file\n",
    "with open(t_path, 'r') as t:\n",
    "    \n",
    "    t_csvreader = csv.reader(t)\n",
    "    t_fields = next(t_csvreader) # getting fields to identify id columns\n",
    "    p1_idx = t_fields.index(\"winner_id\")\n",
    "    p2_idx = t_fields.index(\"loser_id\")\n",
    "    s_idx = t_fields.index(\"surface\")\n",
    "\n",
    "    for t_match in t_csvreader:\n",
    "        p1 = t_match[p1_idx]\n",
    "        p2 = t_match[p2_idx]\n",
    "        s = t_match[s_idx]\n",
    "        # initialize the dict\n",
    "        t_dict_h2h = {}\n",
    "        for field in f_fields:\n",
    "            t_dict_h2h[field] = 0\n",
    "        t_dict_h2h[\"id1\"], t_dict_h2h[\"id2\"], t_dict_h2h[\"surface\"] = p1, p2, s\n",
    "        ovr_list_h2h.append(t_dict_h2h)\n",
    "ovr_list_co = deepcopy(ovr_list_h2h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_int(val):\n",
    "        \"\"\"\n",
    "        some of these entries will be missing, so if an empty string is encountered,\n",
    "        want it just to be 0\n",
    "        \"\"\"\n",
    "        try:\n",
    "            return(int(val))\n",
    "        except ValueError:\n",
    "            return(0)\n",
    "        \n",
    "def update_stats_h2h(list_idx, match, fields, p1w):\n",
    "    \"\"\"\n",
    "    mutates ovr_list_h2h - updates stats for the list_idx's entry with data in match\n",
    "    where p1w indicates whether p1 (name1 in the list entry) was the winner\n",
    "    \"\"\"\n",
    "    \n",
    "    w,l = str(2-p1w),str(1+p1w) # w=1, l=2 if p1w, p1 won; w=2, l=1 otherwise\n",
    "    # indexes of fields needed for statistics\n",
    "    surface = match[fields.index(\"surface\")].lower()\n",
    "    w_ace = fields.index(\"w_ace\")\n",
    "    w_svpt = fields.index(\"w_svpt\")\n",
    "    w_1stWon = fields.index(\"w_1stWon\")\n",
    "    w_2ndWon = fields.index(\"w_2ndWon\")\n",
    "    l_ace = fields.index(\"l_ace\")\n",
    "    l_svpt = fields.index(\"l_svpt\")\n",
    "    l_1stWon = fields.index(\"l_1stWon\")\n",
    "    l_2ndWon = fields.index(\"l_2ndWon\")\n",
    "    \n",
    "    ovr_list_h2h[list_idx][surface+\"_pts_served\"+w] += my_int(match[w_svpt])\n",
    "    ovr_list_h2h[list_idx][surface+\"_service_pts_won\"+w] += my_int(match[w_1stWon]) + my_int(match[w_2ndWon])\n",
    "    ovr_list_h2h[list_idx][surface+\"_pts_received\"+w] += my_int(match[l_svpt])\n",
    "    ovr_list_h2h[list_idx][surface+\"_receiving_pts_won\"+w] += (my_int(match[l_svpt]) - my_int(match[l_1stWon])\n",
    "                                                               - my_int(match[l_2ndWon]))\n",
    "    ovr_list_h2h[list_idx][surface+\"_aces\"+w] += my_int(match[w_ace])\n",
    "    ovr_list_h2h[list_idx][surface+\"_sample_size\"+w] += 1\n",
    "    ovr_list_h2h[list_idx][surface+\"_pts_served\"+l] += my_int(match[l_svpt])\n",
    "    ovr_list_h2h[list_idx][surface+\"_service_pts_won\"+l] += my_int(match[l_1stWon]) + my_int(match[l_2ndWon])\n",
    "    ovr_list_h2h[list_idx][surface+\"_pts_received\"+l] += my_int(match[w_svpt])\n",
    "    ovr_list_h2h[list_idx][surface+\"_receiving_pts_won\"+l] += (my_int(match[w_svpt]) - my_int(match[w_1stWon])\n",
    "                                                               - my_int(match[w_2ndWon]))\n",
    "    ovr_list_h2h[list_idx][surface+\"_aces\"+l] += my_int(match[l_ace])\n",
    "    ovr_list_h2h[list_idx][surface+\"_sample_size\"+l] += 1\n",
    "    \n",
    "# now we can do something similar to the H2H data extraction above\n",
    "# but this time the data of the common opponents isn't extracted\n",
    "# so the update_stats function will be modified\n",
    "def update_stats_co(list_idx, match, fields, p1, pw, method=\"co\"):\n",
    "    \"\"\"\n",
    "    mutates ovr_list_co - updates stats for the list_idx'th entry with data in match\n",
    "    where boolean p1 indicates whether p1 (id1 in the list entry) or p2 is to be updated\n",
    "    and boolean pw indicates whether the player being updated won or lost the match\n",
    "    method designates which of ovr_list_co/co2/co2nsf to update\n",
    "    \"\"\"\n",
    "    \n",
    "    # indexes of fields needed for statistics\n",
    "    if method==\"co\":\n",
    "        surface = match[fields.index(\"surface\")].lower()\n",
    "    elif method==\"co2\":\n",
    "        surface = \"co2\"\n",
    "    else: # method==\"co2nsf\"\n",
    "        surface = \"co2nsf\"\n",
    "    w_ace = fields.index(\"w_ace\")\n",
    "    w_svpt = fields.index(\"w_svpt\")\n",
    "    w_1stWon = fields.index(\"w_1stWon\")\n",
    "    w_2ndWon = fields.index(\"w_2ndWon\")\n",
    "    l_ace = fields.index(\"l_ace\")\n",
    "    l_svpt = fields.index(\"l_svpt\")\n",
    "    l_1stWon = fields.index(\"l_1stWon\")\n",
    "    l_2ndWon = fields.index(\"l_2ndWon\")\n",
    "    \n",
    "    p = \"1\" if p1 else \"2\"\n",
    "    if pw:\n",
    "        ovr_list_co[list_idx][surface+\"_pts_served\"+p] += my_int(match[w_svpt])\n",
    "        ovr_list_co[list_idx][surface+\"_service_pts_won\"+p] += (my_int(match[w_1stWon])\n",
    "                                                                + my_int(match[w_2ndWon]))\n",
    "        ovr_list_co[list_idx][surface+\"_pts_received\"+p] += my_int(match[l_svpt])\n",
    "        ovr_list_co[list_idx][surface+\"_receiving_pts_won\"+p] += (my_int(match[l_svpt])\n",
    "                                                                  - my_int(match[l_1stWon])\n",
    "                                                                  - my_int(match[l_2ndWon]))\n",
    "        ovr_list_co[list_idx][surface+\"_aces\"+p] += my_int(match[w_ace])\n",
    "    else:\n",
    "        ovr_list_co[list_idx][surface+\"_pts_served\"+p] += my_int(match[l_svpt])\n",
    "        ovr_list_co[list_idx][surface+\"_service_pts_won\"+p] += (my_int(match[l_1stWon])\n",
    "                                                                + my_int(match[l_2ndWon]))\n",
    "        ovr_list_co[list_idx][surface+\"_pts_received\"+p] += my_int(match[w_svpt])\n",
    "        ovr_list_co[list_idx][surface+\"_receiving_pts_won\"+p] += (my_int(match[w_svpt])\n",
    "                                                                  - my_int(match[w_1stWon])\n",
    "                                                                  - my_int(match[w_2ndWon]))\n",
    "        ovr_list_co[list_idx][surface+\"_aces\"+p] += my_int(match[l_ace])\n",
    "    ovr_list_co[list_idx][surface+\"_sample_size\"+p] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common Opponent Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "need to first get a list of common opponents for each matchup \n",
    "this will be done by getting 2 lists of played opponents and taking the intersection for each matchup, \n",
    "corresponding 2 lists to be stored in separate lists \n",
    "\"\"\" \n",
    "# initialize the lists of lists\n",
    "# as before, separate lists for co2 to prevent shallow copies\n",
    "ovr_p1_oppo = []\n",
    "ovr_p2_oppo = []\n",
    "for i in range(len(ovr_list_co)):\n",
    "    p1_oppo = []\n",
    "    p2_oppo = []\n",
    "    ovr_p1_oppo.append(p1_oppo)\n",
    "    ovr_p2_oppo.append(p2_oppo)\n",
    "ovr_p1_oppo_co2 = deepcopy(ovr_p1_oppo)\n",
    "ovr_p2_oppo_co2 = deepcopy(ovr_p2_oppo)\n",
    "# go through matches and add opponents\n",
    "for file in f_names:\n",
    "    f_path = matches_path+\"\\\\\"+file\n",
    "    with open(f_path,'r') as f:\n",
    "        csvreader = csv.reader(f)\n",
    "        fields = next(csvreader)\n",
    "        winner_idx = fields.index(\"winner_id\")\n",
    "        loser_idx = fields.index(\"loser_id\")\n",
    "        s_idx = fields.index(\"surface\")\n",
    "        for match in csvreader:\n",
    "            for i in range(len(ovr_list_co)):\n",
    "                if match[winner_idx]==ovr_list_co[i][\"id1\"]:\n",
    "                    ovr_p1_oppo[i].append(match[loser_idx])\n",
    "                    if match[s_idx]==ovr_list_co[i][\"surface\"]:\n",
    "                        ovr_p1_oppo_co2[i].append(match[loser_idx])\n",
    "                elif match[loser_idx]==ovr_list_co[i][\"id1\"]:\n",
    "                    ovr_p1_oppo[i].append(match[winner_idx])\n",
    "                    if match[s_idx]==ovr_list_co[i][\"surface\"]:\n",
    "                        ovr_p1_oppo_co2[i].append(match[winner_idx])\n",
    "                if match[winner_idx]==ovr_list_co[i][\"id2\"]:\n",
    "                    ovr_p2_oppo[i].append(match[loser_idx])\n",
    "                    if match[s_idx]==ovr_list_co[i][\"surface\"]:\n",
    "                        ovr_p2_oppo_co2[i].append(match[loser_idx])\n",
    "                elif match[loser_idx]==ovr_list_co[i][\"id2\"]:\n",
    "                    ovr_p2_oppo[i].append(match[winner_idx])\n",
    "                    if match[s_idx]==ovr_list_co[i][\"surface\"]:\n",
    "                        ovr_p2_oppo_co2[i].append(match[winner_idx])\n",
    "                    \n",
    "# take intersection of each pair of opponent lists for final list of lists\n",
    "ovr_co_oppo = []\n",
    "ovr_co2_oppo = []\n",
    "for i in range(len(ovr_list_co)):\n",
    "    ovr_co_oppo.append(list(set(ovr_p1_oppo[i]).intersection(ovr_p2_oppo[i])))\n",
    "    ovr_co2_oppo.append(list(set(ovr_p1_oppo_co2[i]).intersection(ovr_p2_oppo_co2[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common opponents for 106214 and 202358:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can see the lists of common opponents produced, for example:\n",
    "k = 2\n",
    "print(\"Common opponents for \"+ovr_list_co[k][\"id1\"]+\" and \"+ovr_list_co[k][\"id2\"]+\":\")\n",
    "ovr_co2_oppo[k]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in f_names:\n",
    "    f_path = matches_path+\"\\\\\"+file\n",
    "    with open(f_path,'r') as f:\n",
    "        csvreader = csv.reader(f)\n",
    "        fields = next(csvreader)\n",
    "        winner_idx = fields.index(\"winner_id\")\n",
    "        loser_idx = fields.index(\"loser_id\")\n",
    "        surface_idx = fields.index(\"surface\")\n",
    "        # order of the for loops below cannot(!!!) be reversed - csvreader is not a normal list\n",
    "        for match in csvreader:\n",
    "            for i in range(len(ovr_list_h2h)):\n",
    "                p1 = ovr_list_h2h[i][\"id1\"]\n",
    "                p2 = ovr_list_h2h[i][\"id2\"]\n",
    "                s = ovr_list_h2h[i][\"surface\"]\n",
    "                # h2h\n",
    "                if match[winner_idx]==p1 and match[loser_idx]==p2:\n",
    "                    update_stats_h2h(i,match,fields,p1w=True)\n",
    "                elif match[loser_idx]==p1 and match[winner_idx]==p2:\n",
    "                    update_stats_h2h(i,match,fields,p1w=False)\n",
    "                # co\n",
    "                elif match[winner_idx]==p1 and match[loser_idx] in ovr_co_oppo[i]:\n",
    "                    update_stats_co(i,match,fields,p1=True,pw=True)\n",
    "                    if match[loser_idx] in ovr_co2_oppo[i]:\n",
    "                        update_stats_co(i,match,fields,p1=True,pw=True,method=\"co2nsf\")\n",
    "                        if match[surface_idx]==s:\n",
    "                            update_stats_co(i,match,fields,p1=True,pw=True,method=\"co2\")\n",
    "                elif match[loser_idx]==p1 and match[winner_idx] in ovr_co_oppo[i]:\n",
    "                    update_stats_co(i,match,fields,p1=True,pw=False)\n",
    "                    if match[winner_idx] in ovr_co2_oppo[i]:\n",
    "                        update_stats_co(i,match,fields,p1=True,pw=False,method=\"co2nsf\")\n",
    "                        if match[surface_idx]==s:\n",
    "                            update_stats_co(i,match,fields,p1=True,pw=False,method=\"co2\")\n",
    "                elif match[winner_idx]==p2 and match[loser_idx] in ovr_co_oppo[i]:\n",
    "                    update_stats_co(i,match,fields,p1=False,pw=True)\n",
    "                    if match[loser_idx] in ovr_co2_oppo[i]:\n",
    "                        update_stats_co(i,match,fields,p1=False,pw=True,method=\"co2nsf\")\n",
    "                        if match[surface_idx]==s:\n",
    "                            update_stats_co(i,match,fields,p1=False,pw=True,method=\"co2\")\n",
    "                elif match[loser_idx]==p2 and match[winner_idx] in ovr_co_oppo[i]:\n",
    "                    update_stats_co(i,match,fields,p1=False,pw=False)\n",
    "                    if match[winner_idx] in ovr_co2_oppo[i]:\n",
    "                        update_stats_co(i,match,fields,p1=False,pw=False,method=\"co2nsf\")\n",
    "                        if match[surface_idx]==s:\n",
    "                            update_stats_co(i,match,fields,p1=False,pw=False,method=\"co2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# h2h\n",
    "with open(h2h_path, 'w', newline=\"\") as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=f_fields)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(ovr_list_h2h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# co,co2,co2nsf\n",
    "with open(co_path, 'w', newline=\"\") as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=f_fields)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(ovr_list_co)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
